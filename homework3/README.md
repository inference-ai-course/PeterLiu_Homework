# Homework 3 - Voice-Based Personal AI Assistant

## ğŸ—£ï¸ Overview

This assignment focuses on building a voice-driven AI agent capable of natural conversation using:

- ğŸ¤ **ASR**: Automatic Speech Recognition (Whisper or Faster-Whisper)
- ğŸ§  **LLM**: Local LLM inference (via Ollama running LLaMA3 8B)
- ğŸ”Š **TTS**: Text-to-Speech using Edge-TTS
- ğŸ›œ **FastAPI** backend
- ğŸ§  **Multi-turn memory** and optional wake-word support

---

## ğŸ“ Folder Structure

homework3/
â”œâ”€â”€ audio/ # Input/output audio files
â”œâ”€â”€ main.py # FastAPI backend
â”œâ”€â”€ llm_client.py # Local Ollama query module
â”œâ”€â”€ tts.py # Edge TTS module
â”œâ”€â”€ asr.py # ASR (Faster-Whisper or Whisper.cpp)
â”œâ”€â”€ memory.py # Session-based memory handler
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ Dockerfile # Optional Docker deployment
â”œâ”€â”€ README.md # Project instructions (this file)


---

## ğŸš€ Features

- Upload `.wav` files to `/voice-chat/` API and get `.mp3` replies
- Multi-turn memory using in-memory `session_id`
- Modular structure for ASR / LLM / TTS
- Supports both Whisper (Hugging Face) and Whisper.cpp / Vosk
- Local model inference using Ollama + LLaMA3
- Easily deployable via Docker

---

## ğŸ› ï¸ Setup Instructions

### 1. Install dependencies

```bash
pip install -r requirements.txt

###  ğŸ” API Usage
POST /voice-chat/
Send a .wav file and get AI voice reply.

Request:
curl -X POST http://localhost:8000/voice-chat/ \
  -F "audio=@user_input.wav" \
  -F "session_id=session123" \
  --output reply.mp3
ğŸ§  Memory
Each session is tracked via session_id in memory.
You can extend memory.py to use Redis, SQLite, or LangChain memory later.

ğŸ³ Docker Support
To run everything in Docker:

docker build -t voice-agent .
docker run -p 8000:8000 voice-agent
For Ollama model, run it on your host machine and ensure FastAPI inside Docker can reach http://host.docker.internal:11434

ğŸ§ª Future Work
Real-time streaming audio (WebSocket or MediaStream)

Wake-word detection via porcupine or VAD

Voice UI with Streamlit or web client

Local embedding + RAG integration

âœï¸ Author
Peter Liu
Assignment for: Machine Learning Engineer in the Generative AI Era

---

### âœ… æäº¤åˆ° GitHub

åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œï¼š

```bash
cd ~/PeterLiu_Homework/homework3
touch README.md



git add README.md
git commit -m "Add voice agent README for homework3"
git push origin main
