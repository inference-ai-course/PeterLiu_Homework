{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udce5 Download arXiv cs.CL Papers\n",
        "This notebook downloads the latest 50 papers from arXiv's `cs.CL` (Computation and Language) category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Install required libraries\n",
        "!pip install feedparser tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import feedparser\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcc2 Create a directory to save PDFs\n",
        "save_dir = \"arxiv_cs.CL_pdfs\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd0d Query arXiv API for cs.CL papers\n",
        "base_url = \"http://export.arxiv.org/api/query\"\n",
        "search_query = \"cat:cs.CL\"\n",
        "max_results = 50\n",
        "\n",
        "query = f\"{base_url}?search_query={search_query}&start=0&max_results={max_results}\"\n",
        "feed = feedparser.parse(query)\n",
        "print(f\"Found {len(feed.entries)} papers.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2b07\ufe0f Download each paper's PDF\n",
        "for entry in tqdm(feed.entries):\n",
        "    title = entry.title.replace(\"\\n\", \" \").strip()\n",
        "    pdf_url = None\n",
        "    for link in entry.links:\n",
        "        if link.rel == \"alternate\":\n",
        "            arxiv_id = link.href.split(\"/\")[-1]\n",
        "        if link.type == \"application/pdf\":\n",
        "            pdf_url = link.href\n",
        "\n",
        "    if pdf_url:\n",
        "        try:\n",
        "            response = requests.get(pdf_url)\n",
        "            pdf_path = os.path.join(save_dir, f\"{arxiv_id}.pdf\")\n",
        "            with open(pdf_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {arxiv_id}: {e}\")\n",
        "\n",
        "print(f\"\u2705 Downloaded {len(feed.entries)} PDFs to '{save_dir}'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}