# 🧠 Machine Learning Engineering Homework

This repository contains my homework submissions for the **Machine Learning Engineering (MLE)** program.  
Each week's submission is organized into its own folder (e.g., `homework1/`, `homework2/`), with code, documentation, and screenshots.

---

## 🔗 Project Repository

👉 [PeterLiu_Homework on GitHub](https://github.com/inference-ai-course/PeterLiu_Homework)

---

## 📁 Contents

- `homework1/`: Building a LangChain-based AI agent with Ollama and Gradio
- `homework2/`: End-to-end data pipeline for collecting, extracting, cleaning, and deduplicating web/audio data
- `README.md`: This file

---

## ✅ Week 1 – Build Your First AI Agent

**Goal:** Set up a local LLM workflow and build a plugin-enabled AI assistant.

**What was done:**

- ✅ Installed and ran LLMs locally using **Ollama**
- ✅ Integrated **LangChain** and **Gradio** to build an interactive UI
- ✅ Built a plugin-capable AI agent capable of calling tools such as:
  - Brave Search 🔍
  - Puppeteer for web scraping 📄
  - Filesystem operations 📁
  - Notion and GitHub API integrations 🧠🐙
- ✅ [Optional] Automatically scraped and saved structured data to Notion

---

## ✅ Week 2 – Data Collection & Cleaning Pipeline

**Goal:** Create a reproducible pipeline for collecting and cleaning multimodal data (text, audio, image).

**What was done:**

- ✅ Web scraping (text and PNG) and audio crawling ( `.mp3`)
- ✅ Applied **content extraction**, **language filtering**, and **format standardization**
- ✅ Used **MinHash** + `datasketch` to detect and remove duplicate text data
- ✅ Final dataset stored in a clean, deduplicated **JSONL format**
- ✅ Fully implemented in modular steps via **Jupyter Notebook**

---

## 📸 Screenshots

You can find relevant screenshots in each week's folder if applicable.

Example:

- `homework1/screenshots/`
- `homework2/screenshots/`

---

## 📞 Contact

For any questions or clarifications, feel free to contact me via **Canvas message** or **email**.

---
