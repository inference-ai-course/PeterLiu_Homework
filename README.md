# ğŸ§  Machine Learning Engineering Homework

This repository contains my homework submissions for the **Machine Learning Engineering (MLE)** program.  
Each week's submission is organized into its own folder (e.g., `homework1/`, `homework2/`), with code, documentation, and screenshots.

---

## ğŸ”— Project Repository

ğŸ‘‰ [PeterLiu_Homework on GitHub](https://github.com/inference-ai-course/PeterLiu_Homework)

---

## ğŸ“ Contents

- `homework1/`: Building a LangChain-based AI agent with Ollama and Gradio
- `homework2/`: End-to-end data pipeline for collecting, extracting, cleaning, and deduplicating web/audio data
- `README.md`: This file

---

## âœ… Week 1 â€“ Build Your First AI Agent

**Goal:** Set up a local LLM workflow and build a plugin-enabled AI assistant.

**What was done:**

- âœ… Installed and ran LLMs locally using **Ollama**
- âœ… Integrated **LangChain** and **Gradio** to build an interactive UI
- âœ… Built a plugin-capable AI agent capable of calling tools such as:
  - Brave Search ğŸ”
  - Puppeteer for web scraping ğŸ“„
  - Filesystem operations ğŸ“
  - Notion and GitHub API integrations ğŸ§ ğŸ™
- âœ… [Optional] Automatically scraped and saved structured data to Notion

---

## âœ… Week 2 â€“ Data Collection & Cleaning Pipeline

**Goal:** Create a reproducible pipeline for collecting and cleaning multimodal data (text, audio, image).

**What was done:**

- âœ… Web scraping (text and PNG) and audio crawling ( `.mp3`)
- âœ… Applied **content extraction**, **language filtering**, and **format standardization**
- âœ… Used **MinHash** + `datasketch` to detect and remove duplicate text data
- âœ… Final dataset stored in a clean, deduplicated **JSONL format**
- âœ… Fully implemented in modular steps via **Jupyter Notebook**

---

## ğŸ“¸ Screenshots

You can find relevant screenshots in each week's folder if applicable.

Example:

- `homework1/screenshots/`
- `homework2/screenshots/`

---

## ğŸ“ Contact

For any questions or clarifications, feel free to contact me via **Canvas message** or **email**.

---
