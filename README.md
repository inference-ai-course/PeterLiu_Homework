# ğŸ§  Machine Learning Engineering Homework

This repository contains my homework submissions for the **Machine Learning Engineering (MLE)** program.  
Each week's submission is organized into its own folder (e.g., `homework1/`, `homework2/`, `homework3/`), with code, documentation, and screenshots (if applicable).

---

## ğŸ”— Project Repository

ğŸ‘‰ [PeterLiu_Homework on GitHub](https://github.com/inference-ai-course/PeterLiu_Homework)

---

## ğŸ“ Contents

| Folder       | Description                                                                 |
|--------------|-----------------------------------------------------------------------------|
| `homework1/` | LangChain-based AI agent using Ollama and Gradio                           |
| `homework2/` | End-to-end data pipeline: web/audio scraping, cleaning, deduplication      |
| `homework3/` | Voice-based LLM assistant with ASR, local LLM, and TTS via FastAPI         |
| `README.md`  | This file (overview of all weekly submissions)                             |

---

## âœ… Week 1 â€“ Build Your First AI Agent

### ğŸ¯ Goal:

Set up a local LLM workflow and build a plugin-enabled AI assistant.

### âœ… What was done:

- Installed and ran LLMs locally using **Ollama**
- Integrated **LangChain** and **Gradio** to build an interactive UI
- Built a plugin-capable agent that could call external tools:
  - Brave Search ğŸ”
  - Puppeteer for web scraping ğŸ“„
  - Filesystem tools ğŸ“
  - Notion and GitHub APIs ğŸ§ ğŸ™
- [Optional] Automatically scraped and saved data to **Notion**

---

## âœ… Week 2 â€“ Data Collection & Cleaning Pipeline

### ğŸ¯ Goal:

Create a reproducible pipeline for collecting and cleaning multimodal data (text, audio, image).

### âœ… What was done:

- Performed **web scraping** (text & PNG) and **audio crawling** (.mp3)
- Applied **content extraction**, language filtering, and standardization
- Used **MinHash + datasketch** to detect and remove duplicates
- Saved final clean dataset in **JSONL** format
- All steps implemented as modular **Jupyter Notebooks**

---

## âœ… Week 3 â€“ Build a Local Voice-Based AI Assistant

### ğŸ¯ Goal:

Create a modular voice-based AI assistant that processes voice input and generates spoken responses using local models.

### âœ… What was done:

- Built an **ASR â†’ LLM â†’ TTS** pipeline served via **FastAPI**
- Used **Faster-Whisper** or **Whisper.cpp** to transcribe speech
- Queried **local LLaMA3** model via Ollama for responses
- Converted output text to speech via **Edge-TTS**
- Added **multi-turn memory** to maintain conversational context
- Exposed via `/voice-chat/` API endpoint
- (Optional) Dockerized the entire project for deployment

---

## ğŸ“¸ Screenshots

You can find relevant screenshots in each weekâ€™s folder:

- `homework1/screenshots/`
- `homework2/screenshots/`
- `homework3/screenshots/` (if applicable)

---

## ğŸ“ Contact

For any questions or clarifications, feel free to reach out via Canvas or email.

---


