# ğŸ§  Machine Learning Engineering Homework

This repository contains my homework submissions for the Machine Learning Engineering (MLE) program.  
Each week's submission is organized into its own folder (e.g., `homework1/`, `homework2/`, etc.), with code, documentation, and screenshots (if applicable).

---

## ğŸ”— Project Repository
ğŸ‘‰ [PeterLiu_Homework on GitHub](https://github.com/inference-ai-course/PeterLiu_Homework)

---

## ğŸ“ Contents

| Folder      | Description                                                                 |
|-------------|-----------------------------------------------------------------------------|
| homework1/  | LangChain-based AI agent using Ollama and Gradio                            |
| homework2/  | End-to-end data pipeline: web/audio scraping, cleaning, deduplication       |
| homework3/  | Voice-based LLM assistant with ASR, local LLM, and TTS via FastAPI          |
| homework4/  | Retrieval-Augmented Generation (RAG) system with arXiv papers               |
| homework5/  | Advanced RAG: hybrid retrieval and evaluation framework                     |
| README.md   | This file (overview of all weekly submissions)                              |

---

## âœ… Week 1 â€“ Build Your First AI Agent
ğŸ¯ **Goal:**  
Set up a local LLM workflow and build a plugin-enabled AI assistant.

**What was done:**
- Installed and ran LLMs locally using Ollama  
- Integrated LangChain and Gradio to build an interactive UI  
- Built a plugin-capable agent that could call external tools:
  - Brave Search ğŸ”
  - Puppeteer for web scraping ğŸ“„
  - Filesystem tools ğŸ“
  - Notion and GitHub APIs ğŸ§ ğŸ™  
- (Optional) Automatically scraped and saved data to Notion  

---

## âœ… Week 2 â€“ Data Collection & Cleaning Pipeline
ğŸ¯ **Goal:**  
Create a reproducible pipeline for collecting and cleaning multimodal data (text, audio, image).

**What was done:**
- Performed web scraping (text & PNG) and audio crawling (.mp3)  
- Applied content extraction, language filtering, and standardization  
- Used MinHash + datasketch to detect and remove duplicates  
- Saved final clean dataset in JSONL format  
- All steps implemented as modular Jupyter Notebooks  

---

## âœ… Week 3 â€“ Build a Local Voice-Based AI Assistant
ğŸ¯ **Goal:**  
Create a modular voice-based AI assistant that processes voice input and generates spoken responses using local models.

**What was done:**
- Built an ASR â†’ LLM â†’ TTS pipeline served via FastAPI  
- Used Faster-Whisper or Whisper.cpp to transcribe speech  
- Queried local LLaMA3 model via Ollama for responses  
- Converted output text to speech via Edge-TTS  
- Added multi-turn memory to maintain conversational context  
- Exposed via `/voice-chat/` API endpoint  
- (Optional) Dockerized the entire project for deployment  

---

## âœ… Week 4 â€“ Retrieval-Augmented Generation (RAG) with arXiv Papers
ğŸ¯ **Goal:**  
Build a foundational Retrieval-Augmented Generation (RAG) system tailored to scientific research.  

**What was done:**
- Collected 50 recent arXiv cs.CL PDF papers (via scraping or sample set)  
- Extracted and cleaned text from PDFs using PyMuPDF  
- Chunked documents into â‰¤512-token overlapping segments (sliding window)  
- Generated dense vector embeddings with Sentence-Transformers (`all-MiniLM-L6-v2`)  
- Built a FAISS index (IndexFlatL2) for fast vector similarity search  
- Developed a notebook demo for querying the index and displaying top text chunks  
- Exposed a `/search` FastAPI endpoint to accept queries and return top passages in JSON  

---

## âœ… Week 5 â€“ Advanced RAG with Hybrid Retrieval
ğŸ¯ **Goal:**  
Extend the RAG system with hybrid retrieval (dense + sparse methods) and design an evaluation pipeline for retrieval quality.  

**What was done:**
- Integrated **BM25** retriever with FAISS dense retriever â†’ hybrid retrieval strategy  
- Implemented weighted scoring and rank fusion to combine dense + sparse results  
- Added evaluation using:
  - Recall@K, MRR (Mean Reciprocal Rank), nDCG  
  - Human-in-the-loop spot checks for relevance  
- Enhanced pipeline modularity (retriever registry, configurable backends)  
- Built an interactive notebook for side-by-side retrieval comparison  
- Extended FastAPI service with `/hybrid-search` endpoint  

---

## ğŸ“¸ Screenshots
Screenshots for each homework are stored in the respective folders:
- `homework1/screenshots/`
- `homework2/screenshots/`
- `homework3/screenshots/` (if applicable)  
- `homework4/screenshots/` (run homework4 on GPU server)
- `homework5/screenshots/` (evaluation  demo)  

---

## ğŸ“ Contact
For any questions or clarifications, feel free to reach out via Canvas or email.

